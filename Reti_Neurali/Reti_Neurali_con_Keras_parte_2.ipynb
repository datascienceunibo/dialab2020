{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Laboratorio: Reti Neurali con Keras (parte 2)\n",
    "\n",
    "**Programmazione di Applicazioni Data Intensive**  \n",
    "Laurea in Ingegneria e Scienze Informatiche  \n",
    "DISI - Università di Bologna, Cesena\n",
    "\n",
    "Proff. Gianluca Moro, Roberto Pasolini  \n",
    "`nome.cognome@unibo.it`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "- Importare le librerie necessarie per verificare il funzionamento\n",
    "  - NB: utilizzeremo l'implementazione dell'API Keras interna a TensorFlow (usando il package `tensorflow.keras` invece di `keras`) per consentire facilmente l'esportazione del modello alla fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definire la seguente funzione per scaricare i file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "def download(file, url):\n",
    "    if not os.path.isfile(file):\n",
    "        urlretrieve(url, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ripasso: Reti neurali\n",
    "\n",
    "- Una _rete neurale_ è un modello di apprendimento costituito da molteplici strati di nodi elementari\n",
    "- Ciascun nodo è in pratica un modello di regressione, i cui input sono forniti dallo strato precedente e il cui output è passato a quello successivo\n",
    "  - per modellare relazioni non lineari si applicano agli output dei nodi delle _funzioni di attivazione_, ad es. la funzione _ReLU_\n",
    "- Tramite la _backpropagation_, i parametri (pesi e bias) di tutti i nodi sono addestrati congiuntamente per ottimizzare l'errore della rete tramite discesa gradiente stocastica\n",
    "  - il training set è iterato molteplici volte (_epoche_), ad ogni iterazione le istanze vengono considerate a gruppi (_minibatch_)\n",
    "- Ci sono molti aspetti configurabili (_iperparametri_) nella configurazione e nell'addestramento di una rete\n",
    "  - struttura della rete: numero di strati, numero di nodi in ciascuno, funzione di attivazione, ...\n",
    "  - addestramento: batch size, numero di epoche, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caso di Studio: Riconoscimento Attività Umane\n",
    "\n",
    "- Gli smartphone moderni contengono diversi sensori di movimento, quali accelerometro e oscilloscopio\n",
    "- È possibile raccogliendo dati da questi sensori risconoscere quale attività stia svolgendo una persona?\n",
    "  - È in piedi fermo? Sta camminando? È seduto? ...\n",
    "- Vediamo come addestrare una rete neurale a riconoscere l'attività svolta da una sequenza di letture dei sensori\n",
    "- Tale rete può essere in seguito integrata in un'app per smartphone, ad es. per il tracking di attività fisica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "- Utilizziamo un set di dati di letture da sensori diponibile online su https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones\n",
    "- Sono distinte **6 classi relative a diverse attività** o posizioni...\n",
    "  - camminare, salire scale, scendere scale, seduti, in piedi, sdraiati\n",
    "- ...svolte da 30 persone mentre indossavano uno smartphone\n",
    "- 50 volte al secondo sono stati campionati **9 valori**\n",
    "  - 3 sensori (accelerazione con e senza gravità, rotazione) per 3 assi (XYZ)\n",
    "- Il dataset finale ha **10.299 finestre temporali** (tra training e test) di **128 istanti** l'una, a ciascuna finestra è associata una delle 6 classi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Scarichiamo il dataset in formato ZIP dal Web..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download(\"HARDataset.zip\", \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ...ed estraiamo i file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "if not os.path.isdir(\"UCI HAR Dataset\"):\n",
    "    with ZipFile(\"HARDataset.zip\") as zipf:\n",
    "        zipf.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- I dati sono già divisi in due set `train` e `test`\n",
    "- Nella directory `Inertial Signals` di ciascuno si trovano i file con i dati grezzi ottenuti dai sensori\n",
    "- Sono considerati 3 diversi sensori:\n",
    "  - `total_acc`: accelerazione (accelerometro)\n",
    "  - `body_acc`: accelerazione senza la forza di gravità\n",
    "  - `body_gyro`: rotazione (giroscopio)\n",
    "- Per ogni sensore si considerano tre assi x, y, z come da figura:\n",
    "\n",
    "![x da sinistra verso destra, y dal basso verso l'alto, z da dietro verso davanti](https://developer.android.com/images/axis_device.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- La seguente funzione carica tutti i dati descritti sopra dai file estratti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(prefix, sensors):\n",
    "    def load_file(filepath):\n",
    "        dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "        return dataframe.values\n",
    "    def load_dataset_group(group, prefix, sensors):\n",
    "        filepath = prefix + group + \"/Inertial Signals/\"\n",
    "        filenames = [\"{}_{}_{}.txt\".format(sensor, axis, group)\n",
    "                     for sensor in sensors for axis in \"xyz\"]\n",
    "        X_data = [load_file(filepath + name) for name in filenames]\n",
    "        X = np.dstack(X_data)\n",
    "        y = load_file(prefix + group + '/y_'+group+'.txt').ravel() - 1\n",
    "        return X, y\n",
    "    trainX, trainy = load_dataset_group('train', prefix, sensors)\n",
    "    testX, testy = load_dataset_group('test', prefix, sensors)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Invochiamo la funzione, specificando i sensori per cui vogliamo caricare i dati\n",
    "  - si può eventualmente usare solo una parte dei sensori, ad es. per smartphone dotati solo di alcuni di essi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_dataset(\n",
    "    \"UCI HAR Dataset/\",\n",
    "    [\"total_acc\", \"body_acc\", \"body_gyro\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Otteniamo due dataset \"train\" e \"test\", costituiti rispettivamente da 7.352 e da 2.947 osservazioni (finestre temporali)\n",
    "- Gli array `X_*` a 3 dimensioni (assi) contengono i valori campionati dai sensori\n",
    "  - lungo l'asse 0 abbiamo le N finestre temporali\n",
    "  - lungo l'asse 1 abbiamo i 128 istanti\n",
    "  - lungo l'asse 2 abbiamo i 9 valori campionati per istante (3 sensori per 3 assi)\n",
    "  - in pratica, il valore `[i,j,k]` è il valore di indice k campionato all'instante j nella finestra temporale i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 128, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947, 128, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gli array `y_*` a 1 dimensione contiene le etichette delle finestre temporali\n",
    "  - le etichette sono comprese tra 0 e 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2947,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Carichiamo dal file `activity_labels.txt` i nomi delle attività riconosciute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"UCI HAR Dataset/activity_labels.txt\", \"rt\") as f:\n",
    "    labels = [line.split(\" \")[1].strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WALKING',\n",
       " 'WALKING_UPSTAIRS',\n",
       " 'WALKING_DOWNSTAIRS',\n",
       " 'SITTING',\n",
       " 'STANDING',\n",
       " 'LAYING']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Possiamo usarle per vedere la distribuzione di osservazioni delle diverse attività in training e test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LAYING                1407\n",
       "STANDING              1374\n",
       "SITTING               1286\n",
       "WALKING               1226\n",
       "WALKING_UPSTAIRS      1073\n",
       "WALKING_DOWNSTAIRS     986\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labels)[y_train].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LAYING                537\n",
       "STANDING              532\n",
       "WALKING               496\n",
       "SITTING               491\n",
       "WALKING_UPSTAIRS      471\n",
       "WALKING_DOWNSTAIRS    420\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labels)[y_test].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Codifichiamo le etichette (y) in vettori one-hot da usare come output atteso della rete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "yt_train = to_categorical(y_train)\n",
    "yt_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- I valori in ingresso hanno già media vicina a 0 e dev. standard contenuta, non è necessario standardizzarli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.04749279e-01,  2.87554865e-02,  8.64980163e-02, -6.36303058e-04,\n",
       "       -2.92296856e-04, -2.75299412e-04,  5.06464674e-04, -8.23780831e-04,\n",
       "        1.12948439e-04])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41411195, 0.39099543, 0.35776881, 0.19484634, 0.12242748,\n",
       "       0.10687881, 0.40681506, 0.38185432, 0.25574314])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.std((0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Dalle dimensioni degli array ricaviamo il numero di campioni per osservazione (128), di valori per campione (9) e di possibili classi (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "n_outputs = yt_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Costruiamo una prima rete per la classificazione con un singolo strato nascosto\n",
    "- In input usiamo uno strato `Flatten` per convertire la matrice 128x9 con cui è rappresentata ciascuna osservazione in un vettore di 1.152 elementi\n",
    "  - questo strato cambia solo la rappresentazione dei dati, non introduce nodi o parametri\n",
    "  - con `input_shape` indichiamo la dimensione attesa della matrice\n",
    "- Essendo un problema di classificazione, in output usiamo uno strato con attivazione softmax con 6 nodi, uno per classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(n_timesteps, n_features)),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(n_outputs, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Vediamo la struttura della rete con la forma dell'output e il numero di parametri per ogni strato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,094\n",
      "Trainable params: 37,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Come visto le altre volte, compiliamo il modello specificando\n",
    "  - di utilizzare l'algoritmo di ottimizzazione _Adam_ (variante della discesa gradiente stocastica)\n",
    "  - di ottimizzare (minimizzandola) la _categorical cross entropy_, tanto più alta quanto più le probabilità date alle classi corrette si allontanano dal 100\\%\n",
    "  - di calcolare in parallelo anche l'accuratezza (percentuale di classificazioni corrrette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Addestriamo quindi il modello con `fit`, specificando\n",
    "  - il training set (input e relativi output attesi)\n",
    "  - il numero di epoche di addestramento\n",
    "  - la _batch size_, il numero di osservazioni (finestre temporali) in ciascun minibatch di addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "368/368 [==============================] - 0s 919us/step - loss: 0.7217 - accuracy: 0.7458\n",
      "Epoch 2/10\n",
      "368/368 [==============================] - 0s 914us/step - loss: 0.3206 - accuracy: 0.8945\n",
      "[...]\n",
      "Epoch 9/10\n",
      "368/368 [==============================] - 0s 914us/step - loss: 0.1120 - accuracy: 0.9566\n",
      "Epoch 10/10\n",
      "368/368 [==============================] - 0s 894us/step - loss: 0.1080 - accuracy: 0.9572\n",
      "CPU times: user 4.57 s, sys: 284 ms, total: 4.85 s\n",
      "Wall time: 3.84 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17f264ffd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(X_train, yt_train, epochs=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Usiamo _evaluate_ per calcolare sul validation set le stesse metriche di valutazione mostrate sul training set durante l'addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 949us/step - loss: 0.3685 - accuracy: 0.8907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36853569746017456, 0.8907363414764404]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, yt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'accuratezza (il secondo numero) assume valori indicativamente tra 85\\% e 90\\% (suscettibili di casualità)\n",
    "- Salviamo questo modello in una variabile a parte per vedere successivamente come esportarlo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_export = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Possiamo aggiungere uno strato nascosto per rendere più accurata la rete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(n_timesteps, n_features)),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(n_outputs, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Si noti che il numero di parametri da addestrare si alza sensibilmente..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 156,230\n",
      "Trainable params: 156,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "368/368 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8436\n",
      "Epoch 2/10\n",
      "368/368 [==============================] - 1s 1ms/step - loss: 0.1641 - accuracy: 0.9372\n",
      "[...]\n",
      "Epoch 9/10\n",
      "368/368 [==============================] - 0s 1ms/step - loss: 0.1189 - accuracy: 0.9518\n",
      "Epoch 10/10\n",
      "368/368 [==============================] - 1s 1ms/step - loss: 0.1100 - accuracy: 0.9555\n",
      "CPU times: user 7.34 s, sys: 404 ms, total: 7.74 s\n",
      "Wall time: 5.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17e065cac8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(X_train, yt_train, epochs=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 903us/step - loss: 0.5236 - accuracy: 0.8789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5235555768013, 0.8788598775863647]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, yt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reti convoluzionali\n",
    "\n",
    "- Negli input delle reti neurali è spesso necessario **riconoscere dei pattern** che possono essere presenti **in diverse porzioni** dell'input\n",
    "  - nel caso comune delle immagini, si vogliono riconoscere dei particolari indipendentemente dal punto in cui si trovano\n",
    "  - nel caso di studio corrente, potremmo riconoscere delle sequenze temporali di valori che sono peculiari di attività specifiche\n",
    "- Le reti _convoluzionali_ utilizzano strati con connessioni \"locali\" e pesi condivisi\n",
    "  - ogni nodo riceve input solamente **da nodi vicini tra loro** nello strato inferiore, assumendo che corrispondano a **porzioni di spazio o di tempo**\n",
    "  - **gli stessi pesi sono applicati a tutti i nodi**, in modo lo stesso pattern sia cercato sull'intero intervallo di spazio o di tempo analizzato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Inseriamo all'inizio della rete uno strato `Conv1D` impostando il numero e la lunghezza dei pattern da cercare\n",
    "  - ad esempio poniamo di cercare parallelamente 16 pattern con lunghezza di 15 passi temporali ciascuno\n",
    "- L'output dello strato `Conv1D` sarà un array 2D che indica quali pattern sono stati individuati e in che punto dell'input\n",
    "  - come sopra, applichiamo `Flatten` ad esso per ottenere un vettore lineare di nodi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D\n",
    "model = Sequential([\n",
    "    Conv1D(16, 15, input_shape=(n_timesteps, n_features)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(n_outputs, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Dal sommario, vediamo che lo strato convoluzionale ha un numero di parametri nettamente inferiore rispetto ad un tipico strato denso\n",
    "  - per ognuno dei 16 pattern abbiamo 15x9 pesi e un bias condivisi su 114 nodi, per un totale di 2.176 parametri\n",
    "- Lo strato restituisce 114x16 valori, ovvero 16 pattern cercati nelle 114 (128-15+1) sequenze possibili di 15 valori su 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 114, 16)           2176      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1824)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                116800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 119,366\n",
      "Trainable params: 119,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.5474 - accuracy: 0.8071\n",
      "Epoch 2/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.2083 - accuracy: 0.9233\n",
      "[...]\n",
      "Epoch 9/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.1074 - accuracy: 0.9554\n",
      "Epoch 10/10\n",
      "368/368 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9592\n",
      "CPU times: user 13 s, sys: 532 ms, total: 13.5 s\n",
      "Wall time: 7.53 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17e0549860>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(X_train, yt_train, epochs=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.9033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4774245023727417, 0.9032914638519287]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, yt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reti ricorrenti\n",
    "\n",
    "- Al contrario delle reti viste finora, una rete _ricorrente_ contiene connessioni cicliche tra nodi\n",
    "- A queste reti l'input **è fornito sequenzialmente** in più passi temporali\n",
    "  - nel nostro caso, si immagini di fornire le 128 letture dei sensori una dopo l'altra invece che in blocco\n",
    "- Tramite le connessioni cicliche, **la rete mantiene uno stato** da un passo all'altro\n",
    "- Per usare una rete ricorrente, nei dati di addestramento e test deve essere presente una dimensione temporale\n",
    "  - come nel caso di studio corrente, dove ogni osservazione è una sequenza di 128 campioni\n",
    "- Le reti ricorrenti possono potenzialmente riconoscere correlazioni tra dati forniti in passi temporali diversi, anche distanti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Keras fornisce diversi tipi di strati ricorrenti, tra cui le _Gated Recurrent Unit_ (GRU)\n",
    "  - ad ogni passo temporale $t$ lo strato GRU calcola un output di N valori $h(t)$ in funzione sia dell'input attuale $x(t)$ che dell'output precedente $h(t-1)$\n",
    "- In addestramento e test, dobbiamo fornire le osservazioni complete di tutti gli istanti temporali\n",
    "  - per convenzione Keras tratta una matrice di dimensioni L×M×N come L sequenze di durata M di vettori di misura N\n",
    "  - nel nostro caso, L sequenze di 128 campioni di 9 valori\n",
    "- Di default, solo l'output di GRU all'ultimo passo temporale è considerato per determinare l'output dato dalla rete ad ogni osservazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "model = Sequential([\n",
    "    GRU(64, activation=\"relu\", input_shape=(n_timesteps, n_features)),\n",
    "    Dense(n_outputs, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Anche in questo caso il numero di parametri è molto inferiore rispetto ad un MLP ordinario, in quanto gli stessi pesi vengono riutilizzati attraverso i 128 passaggi temporali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 64)                14400     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 14,790\n",
      "Trainable params: 14,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Il tempo per l'addestramento aumenta, in quanto l'errore su ciascuna osservazione va derivato attraverso i 128 passi temporali (_backpropagation through time_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "74/74 [==============================] - 3s 41ms/step - loss: 1.5351 - accuracy: 0.4452\n",
      "Epoch 2/5\n",
      "74/74 [==============================] - 3s 40ms/step - loss: 1.1608 - accuracy: 0.6066\n",
      "Epoch 3/5\n",
      "74/74 [==============================] - 3s 42ms/step - loss: 0.7020 - accuracy: 0.7014\n",
      "Epoch 4/5\n",
      "74/74 [==============================] - 3s 39ms/step - loss: 0.5566 - accuracy: 0.7675\n",
      "Epoch 5/5\n",
      "74/74 [==============================] - 3s 39ms/step - loss: 0.4402 - accuracy: 0.8251\n",
      "CPU times: user 32.1 s, sys: 1.73 s, total: 33.9 s\n",
      "Wall time: 15.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17e04171d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(X_train, yt_train, epochs=5, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1s 7ms/step - loss: 0.6135 - accuracy: 0.7387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6135448813438416, 0.7387173175811768]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, yt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deployment del modello con TensorFlow Lite\n",
    "\n",
    "- TensorFlow Lite è un framework per il deep learning destinato a dispositivi mobili ed embedded\n",
    "- Si usa per eseguire inferenze (stime e predizioni) su modelli che vengono caricati già addestrati sul dispositivo\n",
    "  - l'inferenza richiede generalmente molte meno risorse rispetto all'addestramento\n",
    "- Sul Web esistono diversi modelli preaddestrati per diversi task\n",
    "  - riconoscimento immagini, natural language processing, ...\n",
    "- Possiamo in aggiunta esportare i modelli addestrati con TensorFlow (anche tramite Keras)\n",
    "- Nel nostro caso di studio, possiamo esportare il modello che riconosce le attività, per poi utilizzarlo ad es. all'interno di un'app mobile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esportazione del modello\n",
    "\n",
    "- Creiamo un oggetto `TFLiteConverter` passando il modello Keras addestrato\n",
    "  - NB: funziona solo su modelli che usano il package `tensorflow.keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_to_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizziamone il metodo `convert` per ottenere la rappresentazione binaria\n",
    "  - NB: eseguendo da Jupyter, si ha errore se TensorFlow è installato in un ambiente virtuale diverso da quello di Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model = bytes()\n",
    "#tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esportiamo quindi tale rappresentazione in un file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.gfile.GFile(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uso all'interno di un'app Android\n",
    "\n",
    "- Vediamo in breve come si integra il modello esportato in un'app Android\n",
    "- Per iniziare, dichiariamo TensorFlow Lite come dipendenza nel file `build.gradle` del progetto\n",
    "\n",
    "```groovy\n",
    "repositories {\n",
    "  // ... altre repository ...\n",
    "  maven {\n",
    "    url 'https://google.bintray.com/tensorflow'\n",
    "  }\n",
    "}\n",
    "dependencies {\n",
    "  // ... altre dipendenze ...\n",
    "  implementation 'org.tensorflow:tensorflow-lite:+'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Un modello TF Lite è rappresentato a run-time da un oggetto `Interpreter`\n",
    "- Creiamo tale oggetto passando un riferimento al file o direttamente un buffer con i dati\n",
    "  - si può trattare di un file salvato nel file system, es. scaricato da Web\n",
    "  - si può anche integrare il modello nell'app (nel file APK), configurandolo in modo che non venga compresso\n",
    "- L'oggetto va generalmente creato all'apertura dell'app (`Activity.onCreate`) e chiuso col metodo `close` alla terminazione (`Activity.onDestroy`)\n",
    "\n",
    "```java\n",
    "import org.tensorflow.lite.Interpreter;\n",
    "...\n",
    "File modelFile = new File(\"/path/to/model.tflite\");\n",
    "Interpreter model = new Interpreter(modelFile);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Per usare il modello vanno allocati per i suoi input e output dei buffer delle giuste dimensioni, che possono essere\n",
    "  - degli array Java (come da esempio sotto)\n",
    "  - oggetti `ByteBuffer` (meno immediati da usare ma più efficienti)\n",
    "\n",
    "```java\n",
    "// array 2D dove inserire l'input da passare alla rete\n",
    "float[][] inputBuffer = new float[seqLength][inputSize];\n",
    "// array in cui verrà scritto l'output della rete\n",
    "float[] outputBuffer = new int[numClasses];\n",
    "```\n",
    "\n",
    "- Ogni volta che si vuole eseguire l'inferenza si usa il metodo `run` dell'`Interpreter`\n",
    "\n",
    "```java\n",
    "model.run(inputBuffer, outputBuffer);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Nel nostro caso di studio, possiamo usare l'API `SensorManager` di Android per eseguire una callback ogni volta che arrivano dati dai sensori\n",
    "- La callback andrà a riportare i dati ricevuti nel buffer di input e ad invocare il modello quando questo viene riempito\n",
    "\n",
    "```java\n",
    "void feedSensorData(int sensor, SensorEvent event) {\n",
    "  // determina a quale passo temporale\n",
    "  // si riferiscono i dati ricevuti\n",
    "  int timestep = ...;\n",
    "  // copia i dati del sensore nel buffer\n",
    "  System.arraycopy(event.values, 0, inputBuffer[inputFillStep],\n",
    "      NUM_AXES * sensor, NUM_AXES);\n",
    "  // se sono arrivato al termine del buffer...\n",
    "  boolean bufferIsFull = ...;\n",
    "  if (bufferIsFull) {\n",
    "    // esegui l'inferenza\n",
    "    inferActivity();\n",
    "    // azzera il buffer di input\n",
    "    resetInputBuffer();\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Quando il buffer è pieno, si passa il contenuto al modello, si ottengono le probabilità delle classi e si verifica qual è la più probabile\n",
    "\n",
    "```java\n",
    "int argmax(float[] values) {\n",
    "  /** Restituisci indice del valore maggiore. */ ...\n",
    "}\n",
    "\n",
    "void inferActivity() {\n",
    "  // eseguo l’inferenza con i dati raccolti\n",
    "  model.run(inputBuffer, outputBuffer);\n",
    "  // verifico la classe con probabilità maggiore\n",
    "  int activityClass = argmax(outputBuffer);\n",
    "  // invoco una callback (ad es. per aggiornare la GUI)\n",
    "  callback.activityInferred(activityClass);\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIA 2020",
   "language": "python",
   "name": "dia2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
